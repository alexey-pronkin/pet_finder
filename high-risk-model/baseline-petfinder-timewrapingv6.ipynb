{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport fastai.vision as fv\nfrom fastai import version\nprint(\"fastai version is {}\".format(version.__version__))\n#API changes: https://github.com/fastai/fastai/blob/33aae8f7b4b7d323d943c178d9ba58afcf8f19b8/CHANGES.md\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n#print(os.listdir(\"../input/train_images/\"))\nrandom_seed=42\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48b9031049c9109614d3891d2a45a80e9deae2f5"},"cell_type":"code","source":"!lscpu","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c70baf16defbb8f5265bbf2eced429c37d550854"},"cell_type":"code","source":"#PATH = \"../working/petfinder-adoption-prediction/\"\n#!cp -r \"../input/petfinder-adoption-prediction/\" \"../working/petfinder-adoption-prediction/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2665cff6fae9504f9c9bd54d47590e06f01ca1cb"},"cell_type":"code","source":"PATH=\"../input/petfinder-adoption-prediction/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c79a8f4b3aedf8ee2a093ed7fe9477202ff8901"},"cell_type":"code","source":"train = pd.read_csv(PATH+\"train/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"86b893cc278662e0a29c66f81c2ec7e7b72b389f"},"cell_type":"code","source":"train_image = pd.DataFrame(os.listdir(PATH+\"train_images/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc3de4c485ea7ba578a26bd0e7e17e85de944742"},"cell_type":"code","source":"image_path = {\"fnames\":[],\"id\":[]}\nfor i in os.listdir(PATH+\"train_images/\"):\n    image_path[\"fnames\"].append(i) \n    image_path[\"id\"].append(i.split(\"-\")[0]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9d1d3f9f774840027ac3564cdc88dd9148e1597"},"cell_type":"code","source":"image_df = pd.DataFrame(image_path)\nimage_df = image_df.merge(right=train[[\"PetID\", \"AdoptionSpeed\"]], left_on=\"id\", right_on=\"PetID\", how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53c0de3838c42c6c65eec89b2efeff19719b2e76"},"cell_type":"code","source":"from sklearn.model_selection import KFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"129841513ac65c7505d51ce0cdae74f49ca99c7b"},"cell_type":"code","source":"cv = KFold(n_splits = 3, random_state = 42, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"815ada7afec3067fddc4ead5590b8f39cffdec2b"},"cell_type":"code","source":"from fastai.torch_core import *\nfrom fastai.vision.image import *\nfrom fastai.vision.transform import *\nfrom fastai.data_block import *\nfrom fastai.basic_data import *\nfrom fastai.layers import *\nfrom fastai.vision.learner import *\nfrom torchvision import transforms as tvt\n\n__all__ = ['get_image_files', 'denormalize', 'get_annotations', 'ImageDataBunch',\n           'ImageList', 'normalize', 'normalize_funcs', 'resize_to',\n           'channel_view', 'mnist_stats', 'cifar_stats', 'imagenet_stats', 'download_images',\n           'verify_images', 'bb_pad_collate', 'ImageImageList', 'PointsLabelList',\n           'ObjectCategoryList', 'ObjectItemList', 'SegmentationLabelList', 'SegmentationItemList', 'PointsItemList']\n\nimage_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))\n\ndef get_image_files(c:PathOrStr, check_ext:bool=True, recurse=False)->FilePathList:\n    \"Return list of files in `c` that are images. `check_ext` will filter to `image_extensions`.\"\n    return get_files(c, extensions=(image_extensions if check_ext else None), recurse=recurse)\n\ndef get_annotations(fname, prefix=None):\n    \"Open a COCO style json in `fname` and returns the lists of filenames (with maybe `prefix`) and labelled bboxes.\"\n    annot_dict = json.load(open(fname))\n    id2images, id2bboxes, id2cats = {}, collections.defaultdict(list), collections.defaultdict(list)\n    classes = {}\n    for o in annot_dict['categories']:\n        classes[o['id']] = o['name']\n    for o in annot_dict['annotations']:\n        bb = o['bbox']\n        id2bboxes[o['image_id']].append([bb[1],bb[0], bb[3]+bb[1], bb[2]+bb[0]])\n        id2cats[o['image_id']].append(classes[o['category_id']])\n    for o in annot_dict['images']:\n        if o['id'] in id2bboxes:\n            id2images[o['id']] = ifnone(prefix, '') + o['file_name']\n    ids = list(id2images.keys())\n    return [id2images[k] for k in ids], [[id2bboxes[k], id2cats[k]] for k in ids]\n\ndef bb_pad_collate(samples:BatchSamples, pad_idx:int=0) -> Tuple[FloatTensor, Tuple[LongTensor, LongTensor]]:\n    \"Function that collect `samples` of labelled bboxes and adds padding with `pad_idx`.\"\n    if isinstance(samples[0][1], int): return data_collate(samples)\n    max_len = max([len(s[1].data[1]) for s in samples])\n    bboxes = torch.zeros(len(samples), max_len, 4)\n    labels = torch.zeros(len(samples), max_len).long() + pad_idx\n    imgs = []\n    for i,s in enumerate(samples):\n        imgs.append(s[0].data[None])\n        bbs, lbls = s[1].data\n        if not (bbs.nelement() == 0):\n            bboxes[i,-len(lbls):] = bbs\n            labels[i,-len(lbls):] = tensor(lbls)\n    return torch.cat(imgs,0), (bboxes,labels)\n\ndef normalize(x:TensorImage, mean:FloatTensor,std:FloatTensor)->TensorImage:\n    \"Normalize `x` with `mean` and `std`.\"\n    return (x-mean[...,None,None]) / std[...,None,None]\n\ndef denormalize(x:TensorImage, mean:FloatTensor,std:FloatTensor, do_x:bool=True)->TensorImage:\n    \"Denormalize `x` with `mean` and `std`.\"\n    return x.cpu().float()*std[...,None,None] + mean[...,None,None] if do_x else x.cpu()\n\ndef _normalize_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Tensor,Tensor]:\n    \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n    x,y = b\n    mean,std = mean.to(x.device),std.to(x.device)\n    if do_x: x = normalize(x,mean,std)\n    if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n    return x,y\n\ndef normalize_funcs(mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Callable,Callable]:\n    \"Create normalize/denormalize func using `mean` and `std`, can specify `do_y` and `device`.\"\n    mean,std = tensor(mean),tensor(std)\n    return (partial(_normalize_batch, mean=mean, std=std, do_x=do_x, do_y=do_y),\n            partial(denormalize,      mean=mean, std=std, do_x=do_x))\n\ncifar_stats = ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261])\nimagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\nmnist_stats = ([0.15]*3, [0.15]*3)\n\ndef channel_view(x:Tensor)->Tensor:\n    \"Make channel the first axis of `x` and flatten remaining axes\"\n    return x.transpose(0,1).contiguous().view(x.shape[1],-1)\n\nclass ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True\n\n    @classmethod\n    def create_from_ll(cls, lls:LabelLists, val_idxs=None, bs:int=64, val_bs:int=None, ds_tfms:Optional[TfmList]=None,\n                num_workers:int=defaults.cpus, dl_tfms:Optional[Collection[Callable]]=None, device:torch.device=None,\n                test:Optional[PathOrStr]=None, collate_fn:Callable=data_collate, size:int=None, no_check:bool=False,\n                resize_method:ResizeMethod=None, mult:int=None, padding_mode:str='reflection',\n                mode:str='bilinear', tfm_y:bool=False)->'ImageDataBunch':\n        \"Create an `ImageDataBunch` from `LabelLists` `lls` with potential `ds_tfms`.\"\n        lls = lls.transform(tfms=ds_tfms, size=size, resize_method=resize_method, mult=mult, padding_mode=padding_mode,\n                            mode=mode, tfm_y=tfm_y)\n        if test is not None: lls.add_test_folder(test)\n        return lls.databunch(bs=bs, val_bs=val_bs, dl_tfms=dl_tfms, num_workers=num_workers, collate_fn=collate_fn,\n                             device=device, no_check=no_check)\n\n    @classmethod\n    def from_folder(cls, path:PathOrStr, train:PathOrStr='train', valid:PathOrStr='valid',\n                    valid_pct=None, classes:Collection=None, **kwargs:Any)->'ImageDataBunch':\n        \"Create from imagenet style dataset in `path` with `train`,`valid`,`test` subfolders (or provide `valid_pct`).\"\n        path=Path(path)\n        il = ImageList.from_folder(path)\n        if valid_pct is None: src = il.split_by_folder(train=train, valid=valid)\n        else: src = il.split_by_rand_pct(valid_pct)\n        src = src.label_from_folder(classes=classes)\n        return cls.create_from_ll(src, **kwargs)\n\n    @classmethod\n    def from_df(cls, path:PathOrStr, df:pd.DataFrame, val_idxs, folder:PathOrStr=None, label_delim:str=None,\n                fn_col:IntsOrStrs=0, label_col:IntsOrStrs=1, suffix:str='', **kwargs:Any)->'ImageDataBunch':\n        \"Create from a `DataFrame` `df`.\"\n        src = (ImageList.from_df(df, path=path, folder=folder, suffix=suffix, cols=fn_col)\n                .split_by_idx(val_idxs)\n                .label_from_df(label_delim=label_delim, cols=label_col))\n        return cls.create_from_ll(src, **kwargs)\n\n    @classmethod\n    def from_csv(cls, path:PathOrStr, folder:PathOrStr=None, label_delim:str=None, csv_labels:PathOrStr='labels.csv',\n                 valid_pct:float=0.2, fn_col:int=0, label_col:int=1, suffix:str='', delimiter:str=None,\n                 header:Optional[Union[int,str]]='infer', **kwargs:Any)->'ImageDataBunch':\n        \"Create from a csv file in `path/csv_labels`.\"\n        path = Path(path)\n        df = pd.read_csv(path/csv_labels, header=header, delimiter=delimiter)\n        return cls.from_df(path, df, folder=folder, label_delim=label_delim, valid_pct=valid_pct,\n                fn_col=fn_col, label_col=label_col, suffix=suffix, **kwargs)\n\n    @classmethod\n    def from_lists(cls, path:PathOrStr, fnames:FilePathList, labels:Collection[str], valid_pct:float=0.2,\n                   item_cls:Callable=None, **kwargs):\n        \"Create from list of `fnames` in `path`.\"\n        item_cls = ifnone(item_cls, ImageList)\n        fname2label = {f:l for (f,l) in zip(fnames, labels)}\n        src = (item_cls(fnames, path=path).split_by_rand_pct(valid_pct)\n                                .label_from_func(lambda x:fname2label[x]))\n        return cls.create_from_ll(src, **kwargs)\n\n    @classmethod\n    def from_name_func(cls, path:PathOrStr, fnames:FilePathList, label_func:Callable, valid_pct:float=0.2, **kwargs):\n        \"Create from list of `fnames` in `path` with `label_func`.\"\n        src = ImageList(fnames, path=path).split_by_rand_pct(valid_pct)\n        return cls.create_from_ll(src.label_from_func(label_func), **kwargs)\n\n    @classmethod\n    def from_name_re(cls, path:PathOrStr, fnames:FilePathList, pat:str, valid_pct:float=0.2, **kwargs):\n        \"Create from list of `fnames` in `path` with re expression `pat`.\"\n        pat = re.compile(pat)\n        def _get_label(fn):\n            if isinstance(fn, Path): fn = fn.as_posix()\n            res = pat.search(str(fn))\n            assert res,f'Failed to find \"{pat}\" in \"{fn}\"'\n            return res.group(1)\n        return cls.from_name_func(path, fnames, _get_label, valid_pct=valid_pct, **kwargs)\n\n    @staticmethod\n    def single_from_classes(path:Union[Path, str], classes:Collection[str], ds_tfms:TfmList=None, **kwargs):\n        \"Create an empty `ImageDataBunch` in `path` with `classes`. Typically used for inference.\"\n        warn(\"\"\"This method is deprecated and will be removed in a future version, use `load_learner` after\n             `Learner.export()`\"\"\", DeprecationWarning)\n        sd = ImageList([], path=path, ignore_empty=True).split_none()\n        return sd.label_const(0, label_cls=CategoryList, classes=classes).transform(ds_tfms, **kwargs).databunch()\n\n    def batch_stats(self, funcs:Collection[Callable]=None)->Tensor:\n        \"Grab a batch of data and call reduction function `func` per channel\"\n        funcs = ifnone(funcs, [torch.mean,torch.std])\n        ds_type = DatasetType.Valid if self.valid_dl else DatasetType.Train\n        x = self.one_batch(ds_type=ds_type, denorm=False)[0].cpu()\n        return [func(channel_view(x), 1) for func in funcs]\n\n    def normalize(self, stats:Collection[Tensor]=None, do_x:bool=True, do_y:bool=False)->None:\n        \"Add normalize transform using `stats` (defaults to `DataBunch.batch_stats`)\"\n        if getattr(self,'norm',False): raise Exception('Can not call normalize twice')\n        if stats is None: self.stats = self.batch_stats()\n        else:             self.stats = stats\n        self.norm,self.denorm = normalize_funcs(*self.stats, do_x=do_x, do_y=do_y)\n        self.add_tfm(self.norm)\n        return self\n\ndef download_image(url,dest, timeout=4):\n    try: r = download_url(url, dest, overwrite=True, show_progress=False, timeout=timeout)\n    except Exception as e: print(f\"Error {url} {e}\")\n\ndef _download_image_inner(dest, url, i, timeout=4):\n    suffix = re.findall(r'\\.\\w+?(?=(?:\\?|$))', url)\n    suffix = suffix[0] if len(suffix)>0  else '.jpg'\n    download_image(url, dest/f\"{i:08d}{suffix}\", timeout=timeout)\n\ndef download_images(urls:Collection[str], dest:PathOrStr, max_pics:int=1000, max_workers:int=8, timeout=4):\n    \"Download images listed in text file `urls` to path `dest`, at most `max_pics`\"\n    urls = open(urls).read().strip().split(\"\\n\")[:max_pics]\n    dest = Path(dest)\n    dest.mkdir(exist_ok=True)\n    parallel(partial(_download_image_inner, dest, timeout=timeout), urls, max_workers=max_workers)\n\ndef resize_to(img, targ_sz:int, use_min:bool=False):\n    \"Size to resize to, to hit `targ_sz` at same aspect ratio, in PIL coords (i.e w*h)\"\n    w,h = img.size\n    min_sz = (min if use_min else max)(w,h)\n    ratio = targ_sz/min_sz\n    return int(w*ratio),int(h*ratio)\n\ndef verify_image(file:Path, idx:int, delete:bool, max_size:Union[int,Tuple[int,int]]=None, dest:Path=None, n_channels:int=3,\n                 interp=PIL.Image.BILINEAR, ext:str=None, img_format:str=None, resume:bool=False, **kwargs):\n    \"Check if the image in `file` exists, maybe resize it and copy it in `dest`.\"\n    try:\n        # deal with partially broken images as indicated by PIL warnings\n        with warnings.catch_warnings():\n            warnings.filterwarnings('error')\n            try:\n                with open(file, 'rb') as img_file: PIL.Image.open(img_file)\n            except Warning as w:\n                if \"Possibly corrupt EXIF data\" in str(w):\n                    if delete: # green light to modify files\n                        print(f\"{file}: Removing corrupt EXIF data\")\n                        warnings.simplefilter(\"ignore\")\n                        # save EXIF-cleaned up image, which happens automatically\n                        PIL.Image.open(file).save(file)\n                    else: # keep user's files intact\n                        print(f\"{file}: Not removing corrupt EXIF data, pass `delete=True` to do that\")\n                else: warnings.warn(w)\n\n        img = PIL.Image.open(file)\n        imgarr = np.array(img)\n        img_channels = 1 if len(imgarr.shape) == 2 else imgarr.shape[2]\n        if (max_size is not None and (img.height > max_size or img.width > max_size)) or img_channels != n_channels:\n            assert isinstance(dest, Path), \"You should provide `dest` Path to save resized image\"\n            dest_fname = dest/file.name\n            if ext is not None: dest_fname=dest_fname.with_suffix(ext)\n            if resume and os.path.isfile(dest_fname): return\n            if max_size is not None:\n                new_sz = resize_to(img, max_size)\n                img = img.resize(new_sz, resample=interp)\n            if n_channels == 3: img = img.convert(\"RGB\")\n            img.save(dest_fname, img_format, **kwargs)\n    except Exception as e:\n        print(f'{e}')\n        if delete: file.unlink()\n\ndef verify_images(path:PathOrStr, delete:bool=True, max_workers:int=4, max_size:Union[int]=None, recurse:bool=False,\n                  dest:PathOrStr='.', n_channels:int=3, interp=PIL.Image.BILINEAR, ext:str=None, img_format:str=None,\n                  resume:bool=None, **kwargs):\n    \"Check if the images in `path` aren't broken, maybe resize them and copy it in `dest`.\"\n    path = Path(path)\n    if resume is None and dest == '.': resume=False\n    dest = path/Path(dest)\n    os.makedirs(dest, exist_ok=True)\n    files = get_image_files(path, recurse=recurse)\n    func = partial(verify_image, delete=delete, max_size=max_size, dest=dest, n_channels=n_channels, interp=interp,\n                   ext=ext, img_format=img_format, resume=resume, **kwargs)\n    parallel(func, files, max_workers=max_workers)\n\nclass ImageList(ItemList):\n    \"`ItemList` suitable for computer vision.\"\n    _bunch,_square_show,_square_show_res = ImageDataBunch,True,True\n    def __init__(self, *args, convert_mode='RGB', after_open:Callable=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.convert_mode,self.after_open = convert_mode,after_open\n        self.copy_new.append('convert_mode')\n        self.c,self.sizes = 3,{}\n\n    def open(self, fn):\n        \"Open image in `fn`, subclass and overwrite for custom behavior.\"\n        return open_image(fn, convert_mode=self.convert_mode, after_open=self.after_open)\n\n    def get(self, i):\n        fn = super().get(i)\n        res = self.open(fn)\n        self.sizes[i] = res.size\n        return res\n    \n    @classmethod\n    def from_folder(cls, path:PathOrStr='.', extensions:Collection[str]=None, **kwargs)->ItemList:\n        \"Get the list of files in `path` that have an image suffix. `recurse` determines if we search subfolders.\"\n        extensions = ifnone(extensions, image_extensions)\n        return super().from_folder(path=path, extensions=extensions, **kwargs)\n\n    @classmethod\n    def from_df(cls, df:DataFrame, path:PathOrStr, cols:IntsOrStrs=0, folder:PathOrStr=None, suffix:str='', **kwargs)->'ItemList':\n        \"Get the filenames in `cols` of `df` with `folder` in front of them, `suffix` at the end.\"\n        suffix = suffix or ''\n        res = super().from_df(df, path=path, cols=cols, **kwargs)\n        pref = f'{res.path}{os.path.sep}'\n        if folder is not None: pref += f'{folder}{os.path.sep}'\n        res.items = np.char.add(np.char.add(pref, res.items.astype(str)), suffix)\n        return res\n\n    @classmethod\n    def from_csv(cls, path:PathOrStr, csv_name:str, header:str='infer', **kwargs)->'ItemList':\n        \"Get the filenames in `path/csv_name` opened with `header`.\"\n        path = Path(path)\n        df = pd.read_csv(path/csv_name, header=header)\n        return cls.from_df(df, path=path, **kwargs)\n\n    def reconstruct(self, t:Tensor): return Image(t.float().clamp(min=0,max=1))\n\n    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        \"Show the `xs` (inputs) and `ys` (targets) on a figure of `figsize`.\"\n        rows = int(np.ceil(math.sqrt(len(xs))))\n        axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize)\n        for x,y,ax in zip(xs, ys, axs.flatten()): x.show(ax=ax, y=y, **kwargs)\n        for ax in axs.flatten()[len(xs):]: ax.axis('off')\n        plt.tight_layout()\n\n    def show_xyzs(self, xs, ys, zs, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        \"Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.\"\n        if self._square_show_res:\n            title = 'Ground truth\\nPredictions'\n            rows = int(np.ceil(math.sqrt(len(xs))))\n            axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=12)\n            for x,y,z,ax in zip(xs,ys,zs,axs.flatten()): x.show(ax=ax, title=f'{str(y)}\\n{str(z)}', **kwargs)\n            for ax in axs.flatten()[len(xs):]: ax.axis('off')\n        else:\n            title = 'Ground truth/Predictions'\n            axs = subplots(len(xs), 2, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=14)\n            for i,(x,y,z) in enumerate(zip(xs,ys,zs)):\n                x.show(ax=axs[i,0], y=y, **kwargs)\n                x.show(ax=axs[i,1], y=z, **kwargs)\n\nclass ObjectCategoryProcessor(MultiCategoryProcessor):\n    \"`PreProcessor` for labelled bounding boxes.\"\n    def __init__(self, ds:ItemList, pad_idx:int=0):\n        super().__init__(ds)\n        self.pad_idx = pad_idx\n        self.state_attrs.append('pad_idx')\n\n    def process(self, ds:ItemList):\n        ds.pad_idx = self.pad_idx\n        super().process(ds)\n\n    def process_one(self,item): return [item[0], [self.c2i.get(o,None) for o in item[1]]]\n\n    def generate_classes(self, items):\n        \"Generate classes from unique `items` and add `background`.\"\n        classes = super().generate_classes([o[1] for o in items])\n        classes = ['background'] + list(classes)\n        return classes\n\ndef _get_size(xs,i):\n    size = xs.sizes.get(i,None)\n    if size is None:\n        # Image hasn't been accessed yet, so we don't know its size\n        _ = xs[i]\n        size = xs.sizes[i]\n    return size\n\nclass ObjectCategoryList(MultiCategoryList):\n    \"`ItemList` for labelled bounding boxes.\"\n    _processor = ObjectCategoryProcessor\n\n    def get(self, i):\n        return ImageBBox.create(*_get_size(self.x,i), *self.items[i], classes=self.classes, pad_idx=self.pad_idx)\n\n    def analyze_pred(self, pred): return pred\n\n    def reconstruct(self, t, x):\n        (bboxes, labels) = t\n        if len((labels - self.pad_idx).nonzero()) == 0: return\n        i = (labels - self.pad_idx).nonzero().min()\n        bboxes,labels = bboxes[i:],labels[i:]\n        return ImageBBox.create(*x.size, bboxes, labels=labels, classes=self.classes, scale=False)\n\nclass ObjectItemList(ImageList):\n    \"`ItemList` suitable for object detection.\"\n    _label_cls,_square_show_res = ObjectCategoryList,False\n\nclass SegmentationProcessor(PreProcessor):\n    \"`PreProcessor` that stores the classes for segmentation.\"\n    def __init__(self, ds:ItemList): self.classes = ds.classes\n    def process(self, ds:ItemList):  ds.classes,ds.c = self.classes,len(self.classes)\n\nclass SegmentationLabelList(ImageList):\n    \"`ItemList` for segmentation masks.\"\n    _processor=SegmentationProcessor\n    def __init__(self, items:Iterator, classes:Collection=None, **kwargs):\n        super().__init__(items, **kwargs)\n        self.copy_new.append('classes')\n        self.classes,self.loss_func = classes,CrossEntropyFlat(axis=1)\n\n    def open(self, fn): return open_mask(fn)\n    def analyze_pred(self, pred, thresh:float=0.5): return pred.argmax(dim=0)[None]\n    def reconstruct(self, t:Tensor): return ImageSegment(t)\n\nclass SegmentationItemList(ImageList):\n    \"`ItemList` suitable for segmentation tasks.\"\n    _label_cls,_square_show_res = SegmentationLabelList,False\n\nclass PointsProcessor(PreProcessor):\n    \"`PreProcessor` that stores the number of targets for point regression.\"\n    def __init__(self, ds:ItemList): self.c = len(ds.items[0].reshape(-1))\n    def process(self, ds:ItemList):  ds.c = self.c\n\nclass PointsLabelList(ItemList):\n    \"`ItemList` for points.\"\n    _processor = PointsProcessor\n\n    def __post_init__(self): self.loss_func = MSELossFlat()\n\n    def get(self, i):\n        o = super().get(i)\n        return ImagePoints(FlowField(_get_size(self.x,i), o), scale=True)\n\n    def analyze_pred(self, pred, thresh:float=0.5): return pred.view(-1,2)\n    def reconstruct(self, t, x): return ImagePoints(FlowField(x.size, t), scale=False)\n\nclass PointsItemList(ImageList):\n    \"`ItemList` for `Image` to `ImagePoints` tasks.\"\n    _label_cls,_square_show_res = PointsLabelList,False\n\nclass ImageImageList(ImageList):\n    \"`ItemList` suitable for `Image` to `Image` tasks.\"\n    _label_cls,_square_show,_square_show_res = ImageList,False,False\n\n    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        \"Show the `xs` (inputs) and `ys`(targets)  on a figure of `figsize`.\"\n        axs = subplots(len(xs), 2, imgsize=imgsize, figsize=figsize)\n        for i, (x,y) in enumerate(zip(xs,ys)):\n            x.show(ax=axs[i,0], **kwargs)\n            y.show(ax=axs[i,1], **kwargs)\n        plt.tight_layout()\n\n    def show_xyzs(self, xs, ys, zs, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        \"Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.\"\n        title = 'Input / Prediction / Target'\n        axs = subplots(len(xs), 3, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=14)\n        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):\n            x.show(ax=axs[i,0], **kwargs)\n            y.show(ax=axs[i,2], **kwargs)\n            z.show(ax=axs[i,1], **kwargs)\n\n\ndef _ll_pre_transform(self, train_tfm:List[Callable], valid_tfm:List[Callable]):\n    \"Call `train_tfm` and `valid_tfm` after opening image, before converting from `PIL.Image`\"\n    self.train.x.after_open = compose(train_tfm)\n    self.valid.x.after_open = compose(valid_tfm)\n    return self\n\ndef _db_pre_transform(self, train_tfm:List[Callable], valid_tfm:List[Callable]):\n    \"Call `train_tfm` and `valid_tfm` after opening image, before converting from `PIL.Image`\"\n    self.train_ds.x.after_open = compose(train_tfm)\n    self.valid_ds.x.after_open = compose(valid_tfm)\n    return self\n\ndef _presize(self, size:int, val_xtra_size:int=32, scale:Tuple[float]=(0.08, 1.0), ratio:Tuple[float]=(0.75, 4./3.),\n             interpolation:int=2):\n    \"Resize images to `size` using `RandomResizedCrop`, passing along `kwargs` to train transform\"\n    return self.pre_transform(\n        tvt.RandomResizedCrop(size, scale=scale, ratio=ratio, interpolation=interpolation), \n        [tvt.Resize(size+val_xtra_size), tvt.CenterCrop(size)])\n\nLabelLists.pre_transform = _ll_pre_transform\nDataBunch.pre_transform = _db_pre_transform\nLabelLists.presize = _presize\nDataBunch.presize = _presize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2ff7844c60d86dffab4bae157d1b08a4ccd9a0c"},"cell_type":"code","source":"image_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7e4eeb7ab63ff3b4938b2d2e7b9c1add3365a7ce"},"cell_type":"code","source":"kappa = fv.KappaScore()\nkappa.weights = \"quadratic\"\nacc_top2 = fv.top_k_accuracy\nacc_top2.k=2\nacc_top1 = fv.top_k_accuracy\nacc_top1.k=1\ndef get_real_val_index(test_index, train, image_df):\n    return list(image_df[\"PetID\"].loc[image_df[\"PetID\"].isin(train[[\"PetID\"]].loc[test_index].values.flatten())].index)\ndata_loaders = []\nlearners = []\n# TODO predictions = np.array()\nfor cv_index, (train_index, test_index) in enumerate(cv.split(train[[\"PetID\", \"AdoptionSpeed\"]])):\n    data_loaders.append(ImageDataBunch.from_df(path=PATH+\"train_images/\",\n                                 df=image_df[[\"fnames\",\"AdoptionSpeed\"]],\n                                 size = (384,512),\n                                 val_idxs = get_real_val_index(test_index, train, image_df),\n                                 resize_method=fv.ResizeMethod.PAD,\n                                 padding_mode='zeros',\n                                 bs=4,\n                                 ds_tfms=fv.get_transforms(flip_vert=False,\n                                                           max_lighting=0.1,\n                                                           max_zoom=1.05,\n                                                           max_warp=0.1,\n                                                           p_affine=0.2)))\n    data_loaders[cv_index].normalize()\n    data_loaders[cv_index].show_batch(rows=4, figsize=(7,6))\n    learners.append(fv.cnn_learner(data_loaders[cv_index], base_arch=fv.models.squeezenet1_0,\n                       metrics=[acc_top1, acc_top2, kappa], \n                       path=\"../working/\", model_dir=\"models/\",\n                       pretrained=True))\n    learners[cv_index].unfreeze()\n    learners[cv_index].fit_one_cycle(1, max_lr=1e-03, div_factor=1.2)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53c0de3838c42c6c65eec89b2efeff19719b2e76","scrolled":false},"cell_type":"code","source":"# categorical_features = [\"Name\", \"Breed1\", \"Breed2\", \"Gender\",\n#                         \"Color1\", \"Color2\", \"Color3\", \"MaturitySize\",\n#                         \"FurLength\", \"Vaccinated\", \"Dewormed\",\n#                        \"Sterilized\", \"Health\", \"Quantity\",\n#                        \"State\", \"RescuerID\", \"VideoAmt\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7429351e2e4f4fb5ec912266d2fe1c9793f4cf5a"},"cell_type":"code","source":"# Adapt from https://www.kaggle.com/mlisovyi/lightgbm-hyperparameter-optimisation-lb-0-761","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89a85e46d6ca3dafb9b0abb91822872a5dfbac7b"},"cell_type":"code","source":"# # TMP_PATH = \"/tmp/tmp\"\n# # MODEL_PATH = \"../input/fastai-pretrained-models/\"\n# !mkdir ../working/models\n\n# !cp ../input/fastai-pretrained-models/*  ../working/models/ \n\n# #Решаем ошибку","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29d8a78fb75419890181a09078dba5ffa5d21e89","scrolled":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6845202a6a776bfa4318b81aff8d8eb540388d0b"},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed35b7962e2c5fd7423533a5d7813c78ebf1cf2d"},"cell_type":"code","source":"lrf = learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89db47912366eeca62925682366f8b1e1bf432df"},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2727aa1eed30cffa11609fd810e5c235e87dc2cb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"589055be0064e41faf41a4a2a09db44a42a284b7"},"cell_type":"code","source":"from fastai.train import ClassificationInterpretation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86b2ef2f5f351b4d9654520027ed817fb34de3ba"},"cell_type":"code","source":"intr = ClassificationInterpretation.from_learner(learn)\nlosses,idxs = intr.top_losses()\nlen(data.valid_ds)==len(losses)==len(idxs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71c976e27f191a21f8fe9701dca954e16be7c34d"},"cell_type":"code","source":"intr.plot_top_losses(9, figsize=(15,11))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3cb1c7c92b85253a0d5105a1f643ad70dfab87d"},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0aeff97090890f7245c5a65b055e3ce8474a9ef8"},"cell_type":"code","source":"learn.fit_one_cycle(4, max_lr=slice(1e-5,1e-2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e396a65b0cf53c7cd9f7a4e221eda7e99d47acbb"},"cell_type":"code","source":"intr.plot_confusion_matrix(figsize=(12,12), dpi=60)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f65883385525437f7c3eff6cdd6f644902d15d90"},"cell_type":"code","source":"#Testing logic of CNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e526963f4d3e4f063c2bde083c2ca8baaab490ab"},"cell_type":"code","source":"x,y = data.valid_ds[idx]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0866c5ae52359cfd774d8af528b2af3633dfb37c"},"cell_type":"code","source":"intr = ClassificationInterpretation.from_learner(learn)\nlosses,idxs = intr.top_losses()\nlen(data.valid_ds)==len(losses)==len(idxs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"437692e760ddb99030889e90cc6e52be1d701e50"},"cell_type":"code","source":"intr.plot_top_losses(9, figsize=(15,11))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"020569755d8765c6c698f127cd1468a632a7d077"},"cell_type":"code","source":"intr.plot_confusion_matrix(figsize=(12,12), dpi=60)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe841fa64429c77a88bf63ae8eb0d7a9bf92f5a9"},"cell_type":"code","source":"from fastai.callbacks.hooks import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76cd2a1445367f6fd626371a3dab20ac8334acda"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42086ab7a1d16bd018460cefb9001b1be8f6751c"},"cell_type":"code","source":"def hooked_backward(cat=y):\n    with hook_output(m[0]) as hook_a: \n        with hook_output(m[0], grad=True) as hook_g:\n            preds = m(xb)\n            preds[0,int(cat)].backward()\n    return hook_a,hook_g","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}