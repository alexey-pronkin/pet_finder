{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1e37ada81c9365229e2fa5655fe97bc5e18fa86"
      },
      "cell_type": "markdown",
      "source": "# The version includes feature extraction\n\n# How to use:\nset `TRAIN_OR_TEST` variable to `TRAIN_OR_TEST = 'train'` to generate features for the train images and `TRAIN_OR_TEST = 'test'` for test images\nyou can specify own backbone model via `model` and `layer` parameters\n"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\n\nimport os\nfrom PIL import Image\nimport gc\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import cohen_kappa_score, make_scorer\nfrom tqdm import tqdm, tqdm_notebook\n\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\n#import torchsummary\nfrom PIL import Image\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "INPUT_PATH = \"../input/petfinder-adoption-prediction/\"\nTRAIN_OR_TEST = 'test'\n\ntrain = pd.read_csv(INPUT_PATH+TRAIN_OR_TEST+'/'+TRAIN_OR_TEST+'.csv') # pd.read_csv(INPUT_PATH+'train/train.csv')\ntrain_image = pd.DataFrame(os.listdir(INPUT_PATH+TRAIN_OR_TEST+'_images/')) # pd.DataFrame(os.listdir(INPUT_PATH+'train_images/'))\n\nimage_path = {\"fnames\":[],\"id\":[], \"pic_id_int\":[]}\nfor i in os.listdir(INPUT_PATH+TRAIN_OR_TEST+'_images/'): # os.listdir(INPUT_PATH+'train_images/'):\n    image_path[\"fnames\"].append(i) \n    image_path[\"id\"].append(i.split(\"-\")[0])\n    image_path[\"pic_id_int\"].append(int(i.split(\"-\")[1].split(\".jpg\")[0]))\n    \nimage_df = pd.DataFrame(image_path)\nif TRAIN_OR_TEST == 'train':\n    image_df = image_df.merge(right=train[[\"PetID\", \"AdoptionSpeed\"]], left_on=\"id\", right_on=\"PetID\", how=\"left\")\nelif TRAIN_OR_TEST == 'test':\n    image_df = image_df.merge(right=train[[\"PetID\"]], left_on=\"id\", right_on=\"PetID\", how=\"left\")\nelse:\n    print(\"TRAIN_OR_TEST is incorrect\")\n\nimage_df = image_df.drop([\"id\"], axis=1)\nimage_df.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9d37dbceaf987948fb3bf84409d7b5dd9c57685"
      },
      "cell_type": "code",
      "source": "image_df_first_img = image_df[image_df.pic_id_int == 1]\nprint(image_df_first_img.shape[0], \"first images\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "710f4b290aa9d1a94dc133aefcfe05101bb360c6"
      },
      "cell_type": "code",
      "source": "# we can load nets without internet:\n# https://github.com/KaiyangZhou/deep-person-reid/issues/23\n# https://www.kaggle.com/rohitgr/fastaiv1-with-densenet121-and-focal-loss/notebook\n#learn.load(\"densenet121-a639ec97\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "04c1c3b1b67fb9d7e015bacde4549280da7d5b5f"
      },
      "cell_type": "markdown",
      "source": "#### load model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "09700a538217c84f2bb4f35486fca65573260121"
      },
      "cell_type": "code",
      "source": "model = models.resnet101(pretrained=True)\n#model = models.densenet121(pretrained=True)\n#model61 = models.densenet161(pretrained=True)\n#model101 = models.resnet101(pretrained=True)\n#model151 = models.resnet152(pretrained=True)\n#modelvgg19 = models.vgg19_bn(pretrained=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7bb3579d33542ad0eadeb7e28a04e100a46f9aee"
      },
      "cell_type": "markdown",
      "source": "#### choose layer"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96f763f4d4d8a9abbd3ac6daabd735fd4a5fec19",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "# you can check output size with torchsummary\n# torchsummary.summary(model, (3, 224, 224))\n# or layer = model._modules.get('avgpool')\nlayer = model.features.norm5\n#layer = model.features.norm5\n#layer161 = model61.features.norm5 # [-1, 2208, 7, 7]           4,416\n#layer101 = model101.avgpool # [-1, 2048, 1, 1]\n#layer151 = model151.avgpool # [-1, 2048, 1, 1]\n#layervgg19 = modelvgg19.avgpool # [-1, 512, 7, 7]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "56c238ea66cb88e20284310041d9ecc791f6aacc"
      },
      "cell_type": "code",
      "source": "_ = model.eval()\n'''\n_ = model61.eval()\n_ = model101.eval()\n_ = model151.eval()\n_ = modelvgg19.eval()\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "abba5b040f238f1a7d123e29db4b8e58b6e2ef3e"
      },
      "cell_type": "markdown",
      "source": "#### Scale and normalize before a network"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93119806258999d75b79ef62dda37586004d280b"
      },
      "cell_type": "code",
      "source": "scaler = transforms.Resize((224, 224))\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\nto_tensor = transforms.ToTensor()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4fa108d8d73a1ce987eae32325316446905e7934"
      },
      "cell_type": "markdown",
      "source": "#### get_vectors() - extract features from a minibatch"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ecb01ec5726b6f23bafb5c9be8a7935e3ff16b3d"
      },
      "cell_type": "code",
      "source": "def get_3d_image(img, image_name):\n    raw_data = np.array(img)\n    #print(\"Raw data shape:\", raw_data.shape)\n    if len(raw_data.shape) == 3 and raw_data.shape[2] == 3:\n        return img\n    elif len(raw_data.shape) == 3 and raw_data.shape[2] == 1:\n        print(\"get_3d_image, case 2:\", image_name)\n        return Image.fromarray(np.stack((img.squeeze(),)*3, axis=-1), 'RGB')\n    elif len(raw_data.shape) == 2:\n        print(\"get_3d_image, case 3:\", image_name)\n        return Image.fromarray(np.stack((img,)*3, axis=-1), 'RGB')\n    else:\n        print(\"error in shape:\", raw_data.shape)\n        return -1\n\nmy_embedding = []\ndef get_vectors(image_names, outp_operation ):\n    global my_embedding\n    t_imges = []\n    for image_name in image_names:\n        # 1. Load the image with Pillow library\n        img = Image.open(image_name)\n        max_size = max(img.height, img.width)\n        h_delta = (max_size - img.height)//2\n        w_delta = (max_size - img.width)//2\n        padding = transforms.Pad((w_delta, h_delta))\n        t_imges.append(normalize(to_tensor(scaler(padding(get_3d_image(img, image_name))))))\n    t_imges = torch.stack(t_imges)\n    \n    def copy_data(module, input, output):\n        my_embedding.append(output.data.squeeze())\n    h = layer.register_forward_hook(copy_data)\n    model(t_imges)\n    h.remove()\n    \n    #print(t_imges.shape)\n    #print(my_embedding[0].detach().numpy().shape)\n    #print(outp_operation(my_embedding[0]).detach().numpy().shape)\n    \n    return outp_operation(my_embedding.pop()).detach().numpy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6a6c61e1baf947e1314b67dbe63dc1eba0456133"
      },
      "cell_type": "markdown",
      "source": "#### test the above extractor"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e5996fae9d75a91b09b5676e32b6399aedcc1316"
      },
      "cell_type": "code",
      "source": "avgPool = nn.AdaptiveAvgPool3d((512,1,1)) # from 32,7,7\npic_one = INPUT_PATH+'train_images/'+'00156db4a-5.jpg'\npic_two = INPUT_PATH+'train_images/'+'00156db4a-4.jpg'\npic_two3 = INPUT_PATH+'train_images/'+'00156db4a-3.jpg'\npic_two2 = INPUT_PATH+'train_images/'+'00156db4a-2.jpg'\npic_two1 = INPUT_PATH+'train_images/'+'00156db4a-1.jpg'\n\npics_vectors = get_vectors([pic_one, pic_two,pic_two3,pic_two2,pic_two1], avgPool)\n\ncnt_new_features = np.prod(pics_vectors[0,:,:,:].shape)\nprint(\"Number of new features:\", cnt_new_features)\nnew_features_names = ['feature' + str(num) for num in range(cnt_new_features)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b665a76dc8614ddbac8836d74bde5695ffa53cca"
      },
      "cell_type": "code",
      "source": "X_img_names = INPUT_PATH + TRAIN_OR_TEST + '_images/' + np.array(image_df_first_img.fnames)\nX_ids = np.array(image_df_first_img.PetID)\ny = None\nif TRAIN_OR_TEST == 'train':\n    y = np.array(image_df_first_img.AdoptionSpeed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2897ba91aaa47a08ae54a8c96dd8a7f0cb021534"
      },
      "cell_type": "markdown",
      "source": "#### simulation of the batch loading"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c7238be5738fea0158db6d4254079d5eac63f2db"
      },
      "cell_type": "code",
      "source": "'''\nbatch_size = 100\nX_features_train = get_vectors(X_img_names[:batch_size], avgPool).reshape(batch_size, cnt_new_features)\ny_train = y[:batch_size]\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0ee7c77768c9cd38d8989d64da0162ebf1c6d6ac"
      },
      "cell_type": "markdown",
      "source": "#### generate features\n~ 2 min for 10 iterations = for 1000 examples"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ab40f51a0dc4620ece5af039ca9e842ca7e511f"
      },
      "cell_type": "code",
      "source": "# We cannot sent batch size 14k+ to the net. let's do batch size ~500 and create features in a loop\nprint(\"Number of images to generate fetures:\", X_img_names.shape)\ncnt_batchs = 300\nif TRAIN_OR_TEST == 'train':\n    cnt_batchs = 300\nelse:\n    cnt_batchs = 60\nbatch_ends_ids = np.linspace(50, len(X_img_names), cnt_batchs, dtype=int)\nlast_end_id = 0\nX_features = []\nfor i in tqdm_notebook(range(cnt_batchs)):\n    batch_size = batch_ends_ids[i] - last_end_id\n    X_features.append(get_vectors(X_img_names[last_end_id:batch_ends_ids[i]], avgPool).reshape(batch_size, cnt_new_features))\n    last_end_id = batch_ends_ids[i]\nprint(\"Stack batches in the feature list\")\nX_features = np.vstack(X_features)\n\nnp.save('X_features_resnet101'+TRAIN_OR_TEST, X_features)\nnp.save('X_img_names_resnet101'+TRAIN_OR_TEST, X_img_names)\nif TRAIN_OR_TEST == 'train':\n    np.save('y_resnet101'+TRAIN_OR_TEST, y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "22901cd0dd24ee4b1b530e8d91eda760050f5221"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "007c6699d530b0d76295d22196064fc91c21e85e"
      },
      "cell_type": "markdown",
      "source": "## Now, I am loading data from the outputs above"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b8d4ff3e9ffdee812f0cc356a24c88814acc4af"
      },
      "cell_type": "code",
      "source": "X_features = np.load('./X_features_resnet101.npy')\nX_img_names = np.load('./X_img_names_resnet101.npy')\ny = np.load('./y_resnet101.npy')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "68de5ab2497aca097e06f9f393bf83d9c0aafc6b"
      },
      "cell_type": "markdown",
      "source": "#### get dummy labels from $y \\in \\{0,1,2,3,4\\}$. WE DO NOT USE THE FUNCTIONS HERE"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "236f5ada4a3a67ff0354fe750dc8bd4e7cfad4ae"
      },
      "cell_type": "code",
      "source": "# input example: get_hard_dummy([0,1,2,1])\ndef get_hard_dummy(y, cnt_labels=5):\n    dummies = np.zeros((len(y), cnt_labels))\n    for idx, label in zip(range(len(y)), y):\n        dummies[idx, label] = 1.0\n    return dummies\n\n# for y=1 return [0.3, 1, 0.3, 0, 0] instead of [0, 1, 0, 0, 0]\ndef get_soft_dummy(y, soft_zero = 0.3, cnt_labels=5):\n    dummies = np.zeros((len(y), cnt_labels))\n    for idx, label in zip(range(len(y)), y):\n        dummies[idx, label] = 1.0\n        if label == 0:\n            dummies[idx, 1] = soft_zero\n        elif label == cnt_labels - 1:\n            dummies[idx, cnt_labels - 2] = soft_zero\n        else:\n            dummies[idx, label - 1], dummies[idx, label + 1] = soft_zero, soft_zero\n    return dummies",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8aaa7ab6520c8e8939e13644b68ec0373e65806f"
      },
      "cell_type": "markdown",
      "source": "#### Kappa Score"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2cf18341c8c24ab8ffa90a0066a9dafcbba8d0a6"
      },
      "cell_type": "code",
      "source": "# The following 3 functions have been taken from Ben Hamner's github repository\n# https://github.com/benhamner/Metrics\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e011eeb9ed150f38cbe0a50004e70fb29d03d118"
      },
      "cell_type": "markdown",
      "source": "#### LGBM on features"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fc32f50bbb695734038e759d687813286e43fc4"
      },
      "cell_type": "code",
      "source": "if TRAIN_OR_TEST == 'train':\n    kappa_scorer = make_scorer(quadratic_weighted_kappa)\n    kf = model_selection.KFold(n_splits = 5, random_state = 42, shuffle = True)\n    model = lgb.LGBMClassifier(n_jobs=-1, random_state=42, n_estimators=500, reg_alpha=1.3, reg_lambda=1.3)\n    scores = model_selection.cross_val_score(model, X_features, y, cv=kf, scoring = kappa_scorer)\n    scores",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "62f3e822544669a40e3d0fe0e2f14d4da60506cc"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}